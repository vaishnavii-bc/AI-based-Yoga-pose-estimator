{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78697ec5",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb714b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a152767",
   "metadata": {},
   "source": [
    "# Mediapipe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e75ecd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2964d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    result = model.process(image)\n",
    "    return image, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "022ab3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2), \n",
    "                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2) \n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78075a39",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bdbe44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1724e2ab",
   "metadata": {},
   "source": [
    "# Class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c44197",
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = ['Adho', 'Alanasana', 'Anjaneyasana', 'Ardha', 'Ashta', 'Baddha', 'Bakasana', 'Balasana', 'Bandha', \n",
    "              'Bhujangasana', 'Bitilasana', 'Camatkarasana', 'Chandrasana', 'Dhanurasana', 'Eka', 'Garudasana', \n",
    "              'Halasana', 'Hanumanasana', 'Hasta', 'Kapotasana', 'Konasana', 'Malasana', 'Marjaryasana', 'Matsyendrasana', \n",
    "              'Mayurasana', 'Mukha', 'Navasana', 'One', 'Pada', 'Padangusthasana', 'Padmasana', 'Parsva', 'Parsvakonasana', \n",
    "              'Parsvottanasana', 'Paschimottanasana', 'Phalakasana', 'Pincha', 'Rajakapotasana', 'Salamba', 'Sarvangasana',\n",
    "              'Setu', 'Sivasana', 'Supta', 'Svanasana', 'Svsnssana', 'Three', 'Trikonasana', 'Two', 'Upavistha', 'Urdhva', \n",
    "              'Ustrasana', 'Utkatasana', 'Uttanasana', 'Utthita', 'Vasisthasana', 'Virabhadrasana', 'Vrksasana']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef4be52",
   "metadata": {},
   "source": [
    "# Testing rough "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e0796f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('Padamasama.jpg')\n",
    "output = model(image, show=True)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e918571",
   "metadata": {},
   "source": [
    "# Integrate with mediapipe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd422bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb9896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Padamasama.jpg')\n",
    "results = model(image, show=False)[0]\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1,y1,x2,y2,score,class_id = result\n",
    "        cv2.rectangle(image, (int(x1),int(y1)), (int(x2),int(y2)), (255,0,0), 2)\n",
    "        \n",
    "        image, out = mediapipe_detection(image,pose)\n",
    "        \n",
    "        draw_landmarks(image, out)\n",
    "        plt.imshow(image[:,:,::-1])\n",
    "        plt.title(classnames[int(class_id)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e2c5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.names.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d449da",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('Anjaneyasana.jpg')\n",
    "results = model(image, show=False)[0]\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1,y1,x2,y2,score,class_id = result\n",
    "        cv2.rectangle(image, (int(x1),int(y1)), (int(x2),int(y2)), (255,0,0), 2)\n",
    "        \n",
    "        image, out = mediapipe_detection(image,pose)\n",
    "        \n",
    "        draw_landmarks(image, out)\n",
    "        \n",
    "        plt.imshow(image[:,:,::-1])\n",
    "        plt.title(classnames[int(class_id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ea908",
   "metadata": {},
   "source": [
    "# Tesing with video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0f2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow('Sample', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89af97f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1800)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1200)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow('video', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "698978f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = []\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1800)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1200)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        results = model(frame, show=False)[0]\n",
    "        \n",
    "        for result in results.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = result\n",
    "            \n",
    "            cv2.rectangle(frame, (int(x1),int(y1)), (int(x2),int(y2)), (0,0,255), 4)\n",
    "            \n",
    "            cv2.rectangle(frame, (10,10), (300,80), (255,0,0), -1)\n",
    "            cv2.putText(frame, classnames[int(class_id)], (40,50), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 1)\n",
    "            \n",
    "            try:\n",
    "                if class_id:\n",
    "                    now = datetime.now()\n",
    "                    start_time = now.strftime(\"%H:%M:%S\")\n",
    "                    time_stamp.append(start_time)\n",
    "\n",
    "                    t1 = datetime.strptime(time_stamp[0], \"%H:%M:%S\")\n",
    "\n",
    "                    t2 = datetime.strptime(time_stamp[-1], \"%H:%M:%S\")\n",
    "\n",
    "                    delta = (t2 - t1)\n",
    "                    df = \"Hold this Exercise position for \"+str(8-int(delta.total_seconds()))+\" sec.\"\n",
    "                    if 8-int(delta.total_seconds())<0:\n",
    "                        df = \"YOU COMPLETED THIS SET\"\n",
    "                    \n",
    "                    cv2.rectangle(frame, (1500,12),(900,73),(23,210,28),-1)\n",
    "                    cv2.putText(frame,str(df) ,(920,40),cv2.FONT_HERSHEY_COMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "                \n",
    "                else:\n",
    "                    time_stamp = []\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            image, out = mediapipe_detection(frame,pose)\n",
    "        \n",
    "            draw_landmarks(image, out)\n",
    "            \n",
    "            cv2.imshow('Output', frame)\n",
    "            \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9eb69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d25404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_stamp = []\n",
    "\n",
    "# count = 2\n",
    "\n",
    "# yoga = 'Adho'\n",
    "\n",
    "# newName = ['Adho', 'Alanasana', 'Anjaneyasana', 'Ardha', 'Ashta', 'Baddha', 'Bakasana', 'Balasana', 'Bandha', \n",
    "#               'Bhujangasana', 'Bitilasana', 'Camatkarasana', 'Chandrasana', 'Dhanurasana', 'Eka', 'Garudasana', \n",
    "#               'Halasana', 'Hanumanasana', 'Hasta', 'Kapotasana', 'Konasana', 'Malasana', 'Marjaryasana', 'Matsyendrasana', \n",
    "#               'Mayurasana', 'Mukha', 'Navasana', 'One', 'Pada', 'Padangusthasana', 'Parsva', 'Parsvakonasana', \n",
    "#               'Parsvottanasana', 'Paschimottanasana', 'Phalakasana', 'Pincha', 'Rajakapotasana', 'Salamba', 'Sarvangasana',\n",
    "#               'Setu', 'Sivasana', 'Supta', 'Svanasana', 'Svsnssana', 'Three', 'Trikonasana', 'Two', 'Upavistha', 'Urdhva', \n",
    "#               'Ustrasana', 'Utkatasana', 'Uttanasana', 'Utthita', 'Vasisthasana', 'Virabhadrasana', 'Vrksasana']\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1800)\n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1200)\n",
    "\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "#     while True:\n",
    "        \n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         results = model(frame, show=False)[0]\n",
    "        \n",
    "#         for result in results.boxes.data.tolist():\n",
    "#             x1, y1, x2, y2, score, class_id = result\n",
    "            \n",
    "#             cv2.rectangle(frame, (int(x1),int(y1)), (int(x2),int(y2)), (0,0,255), 4)\n",
    "            \n",
    "#             cv2.rectangle(frame, (10,10), (300,80), (255,0,0), -1)\n",
    "#             #cv2.putText(frame, classnames[int(class_id)], (40,50), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 1)\n",
    "#             cv2.putText(frame, yoga, (40,50), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 1)\n",
    "            \n",
    "#             try:\n",
    "#                 if yoga in newName:\n",
    "#                     now = datetime.now()\n",
    "#                     start_time = now.strftime(\"%H:%M:%S\")\n",
    "#                     time_stamp.append(start_time)\n",
    "#                     t1 = datetime.strptime(time_stamp[0], \"%H:%M:%S\")\n",
    "\n",
    "#                     t2 = datetime.strptime(time_stamp[-1], \"%H:%M:%S\")\n",
    "\n",
    "#                     delta = (t2 - t1)\n",
    "#                     print(delta)\n",
    "#                     for i in range(count):\n",
    "#                         cv2.rectangle(frame, (1500, 25), (1000, 140), (0, 0, 255), -1)\n",
    "#                         cv2.rectangle(frame, (1500, 12), (900, 73), (23, 210, 28), -1)\n",
    "#                         for sec in range(8, 0, -1):\n",
    "#                             df = \"Hold this Exercise position for \" + str(sec) + \" sec.\"\n",
    "#                             cv2.putText(frame, str(df), (920, 40), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "#                             dfs = f\"YOU COMPLETED {i} SET\"\n",
    "#                             cv2.putText(frame, str(dfs), (1050, 110), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "#                             print(i)\n",
    "            \n",
    "                \n",
    "#                 else:\n",
    "#                     time_stamp = []\n",
    "            \n",
    "#             except:\n",
    "#                 pass\n",
    "                \n",
    "#             image, out = mediapipe_detection(frame,pose)\n",
    "        \n",
    "#             draw_landmarks(image, out)\n",
    "            \n",
    "#             cv2.imshow('Output', frame)\n",
    "            \n",
    "#         if cv2.waitKey(1) == ord('q'):\n",
    "#                 break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aef44f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = []\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1800)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1200)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        results = model(frame, show=False)[0]\n",
    "        \n",
    "        for result in results.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, score, class_id = result\n",
    "            \n",
    "            cv2.rectangle(frame, (int(x1),int(y1)), (int(x2),int(y2)), (0,0,255), 4)\n",
    "            \n",
    "            cv2.rectangle(frame, (10,10), (300,80), (255,0,0), -1)\n",
    "            cv2.putText(frame, classnames[int(class_id)], (40,50), cv2.FONT_HERSHEY_DUPLEX, 1, (0,255,0), 1)\n",
    "            \n",
    "                \n",
    "            image, out = mediapipe_detection(frame,pose)\n",
    "        \n",
    "            draw_landmarks(image, out)\n",
    "            \n",
    "            cv2.imshow('Output', frame)\n",
    "            \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824896a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poseenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
